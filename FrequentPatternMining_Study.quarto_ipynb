{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Study Notes: Data Mining - Chapter 6**\n",
        "## **Frequent Pattern Mining, Association Rules, and Correlation Analysis**\n",
        "\n",
        "### **1. What is Frequent Pattern Mining?**\n",
        "- **Definition:** A frequent pattern is a set of items, sequences, or structures that **appear frequently** in a dataset.\n",
        "- **First introduced** by Agrawal, Imielinski, and Swami (1993) in the context of **association rule mining**.\n",
        "- **Applications:**\n",
        "  - Market Basket Analysis\n",
        "  - Web Log Analysis\n",
        "  - DNA Sequence Analysis\n",
        "  - Social Network Mining\n",
        "\n",
        "### **2. Market Basket Analysis**\n",
        "- **Goal:** Identify **associations** between items frequently bought together.\n",
        "- **Example:** \n",
        "  - **Association Rule:** `{Laptop} â†’ {Mouse}` (If a laptop is bought, a mouse is also likely bought)\n",
        "  - **Support:** Probability that both items appear together in transactions.\n",
        "  - **Confidence:** Probability that a transaction containing `{Laptop}` also contains `{Mouse}`.\n",
        "\n",
        "### **3. Key Measures for Association Rules**\n",
        "1. **Support:**  \n",
        "   Measures how frequently an itemset appears in the dataset.  \n",
        "   $$\n",
        "   Support(A \\Rightarrow B) = P(A \\cup B)\n",
        "   $$\n",
        "2. **Confidence:**  \n",
        "   Measures how often **B** appears in transactions containing **A**.  \n",
        "   $$\n",
        "   Confidence(A \\Rightarrow B) = P(B | A) = \\frac{Support(A \\cup B)}{Support(A)}\n",
        "   $$\n",
        "3. **Lift:**  \n",
        "   Measures how much more likely **A and B** occur together compared to **independent** occurrences.  \n",
        "   $$\n",
        "   Lift(A \\Rightarrow B) = \\frac{P(A \\cup B)}{P(A) P(B)}\n",
        "   $$\n",
        "   - **Lift > 1:** A and B are positively correlated.\n",
        "   - **Lift < 1:** A and B are negatively correlated.\n",
        "\n",
        "### **4. Frequent Itemsets and Rule Generation**\n",
        "- **Frequent Itemset:** A set of items appearing together in at least **min_support** transactions.\n",
        "- **Strong Rules:** Rules that meet **min_support** and **min_confidence**.\n",
        "- **Example:**\n",
        "  - **Transactions:**\n",
        "    ```\n",
        "    {Milk, Bread, Diaper}\n",
        "    {Milk, Bread}\n",
        "    {Milk, Diaper}\n",
        "    {Bread, Diaper}\n",
        "    ```\n",
        "  - **Frequent Itemsets (min_support = 50%):**\n",
        "    ```\n",
        "    {Milk, Bread} â†’ 50%\n",
        "    {Milk, Diaper} â†’ 50%\n",
        "    ```\n",
        "\n",
        "### **5. Apriori Algorithm (Breadth-First Search)**\n",
        "- **Key Idea:** Uses the **downward closure property** â€“ if an itemset is **frequent**, then all its subsets must also be frequent.\n",
        "- **Steps:**\n",
        "  1. Find frequent **1-itemsets**.\n",
        "  2. Generate candidate **2-itemsets** from 1-itemsets.\n",
        "  3. Keep itemsets with **min_support**.\n",
        "  4. Repeat for **k-itemsets** until no more frequent itemsets exist.\n",
        "- **Limitations:**\n",
        "  - Multiple database scans.\n",
        "  - High computational cost for large datasets.\n",
        "\n",
        "### **6. FP-Growth Algorithm (Depth-First Search)**\n",
        "- **Key Idea:** Uses **tree structures (FP-Tree)** to avoid candidate generation.\n",
        "- **Steps:**\n",
        "  1. Construct an **FP-Tree** (compressed representation of transactions).\n",
        "  2. Use **recursive pattern growth** to mine frequent itemsets.\n",
        "  - **Advantages over Apriori:**\n",
        "    - Faster (avoids candidate generation).\n",
        "    - Uses less memory.\n",
        "\n",
        "### **7. Correlation Analysis & Alternative Interestingness Measures**\n",
        "- **Limitations of Confidence:** Can be misleading when items are **independent**.\n",
        "- **Alternative Measures:**\n",
        "  - **Kulczynski Measure:**\n",
        "    $$\n",
        "    Kulc(A, B) = \\frac{1}{2} (P(A | B) + P(B | A))\n",
        "    $$\n",
        "  - **Cosine Similarity:**\n",
        "    $$\n",
        "    Cosine(A, B) = \\frac{P(A \\cup B)}{\\sqrt{P(A) P(B)}}\n",
        "    $$\n",
        "  - **Chi-Square Test:**\n",
        "    $$\n",
        "    \\chi^2 = \\sum \\frac{(O_{ij} - E_{ij})^2}{E_{ij}}\n",
        "    $$\n",
        "  - **Interest Factor:**\n",
        "    $$\n",
        "    Interest(A, B) = \\frac{P(A \\cup B)}{P(A) P(B)}\n",
        "    $$\n",
        "\n",
        "### **8. Null Transactions and Null-Invariance**\n",
        "- **Null Transactions:** Transactions that do not contain **A** or **B**.\n",
        "- **Issue:** Some measures (like Lift) are **not null-invariant**, meaning they are affected by the number of null transactions.\n",
        "- **Null-Invariant Measures:** Kulczynski, Cosine, Jaccard.\n",
        "\n",
        "---\n",
        "\n",
        "## **Summary**\n",
        "- **Frequent pattern mining** identifies relationships between items in transactions.\n",
        "- **Support, confidence, and lift** are key metrics for association rules.\n",
        "- **Apriori algorithm** uses **candidate generation**, while **FP-Growth** eliminates it with **tree-based mining**.\n",
        "- **Correlation measures** like **Kulczynski, Chi-Square, and Interest Factor** provide alternative interestingness criteria.\n",
        "\n",
        "---\n",
        "\n",
        "Let me know if you need modifications! ðŸš€"
      ],
      "id": "5e124d47"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "c:\\Users\\Shauna\\demo-project\\.venv\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}